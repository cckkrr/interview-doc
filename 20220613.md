# java语言的特点

1. 简单易学；

2. ⾯向对象（封装，继承，多态）；
3. 平台⽆关性（ Java 虚拟机实现平台⽆关性）；
4.  可靠性；
5. 安全性；
6.  ⽀持多线程（ C++ 语⾔没有内置的多线程机制，因此必须调⽤操作系统的多线程功能来进⾏多线程程序设计，⽽ Java 语⾔却提供了多线程⽀持）；
7.  ⽀持⽹络编程并且很⽅便（ Java 语⾔诞⽣本身就是为简化⽹络编程设计的，因此 Java 语
   ⾔不仅⽀持⽹络编程⽽且很⽅便）；
8.  编译与解释并存；  

# 面向对象和面向过程的区别

1. ⾯向过程 ： ⾯向过程性能⽐⾯向对象⾼。 因为类调⽤时需要实例化，开销⽐较⼤，⽐较消
   耗资源，所以当性能是最重要的考量因素的时候，⽐如单⽚机、嵌⼊式开发、 Linux/Unix 等
   ⼀般采⽤⾯向过程开发。但是， ⾯向过程没有⾯向对象易维护、易复⽤、易扩展。
2. ⾯向对象 ： ⾯向对象易维护、易复⽤、易扩展。 因为⾯向对象有封装、继承、多态性的特
   性，所以可以设计出低耦合的系统，使系统更加灵活、更加易于维护。但是， ⾯向对象性能
   ⽐⾯向过程低。  

# http、https区别

HTTP（HyperText Transfer Protocol）：超文本（文本、图片、视频、音频、css、js....）传输协议 ，它是基于请求/响应模式、应用层（TCP/IP协议）、无状态（没有记忆功能）的协议。HTTP 协议是以明文方式发送信息的，如果黑客截取了 Web 浏览器和服务器之间的传输报文，就可以直接获得其中的信息。

HTTPS（Hyper Text Transfer Protocol over SecureSocket Layer）：是以安全为目标的 HTTP 通道，是 HTTP 的安全版。HTTPS 的安全基础是 SSL。SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。SSL 协议可分为两层：SSL 记录协议（SSL Record Protocol），它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。SSL 握手协议（SSL Handshake Protocol），它建立在 SSL 记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。

区别：

1、HTTPS  协议需要到 CA （Certificate Authority，证书颁发机构）申请证书，一般免费证书较少，因而需要一定费用。(以前的网易官网是http，而网易邮箱是 https 。)

2、HTTP 是超文本传输协议，信息是明文传输，HTTPS 则是具有安全性的 SSL 加密传输协议。

3、HTTP 和 HTTPS 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、HTTP 的连接很简单，是无状态的。HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。(无状态的意思是其数据包的发送、传输和接收都是相互独立的。无连接的意思是指通信双方都不长久的维持对方的任何信息。)
————————————————
版权声明：本文为CSDN博主「爱敲代码的狼仔」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_48469083/article/details/121848871



# https加密

https就使用“对称加密+非对称加密”组合的方式做加密流程的。具体如下：
        1，浏览器使用Https的URL访问服务器，建立SSL链接。
        2，服务器接收到SSL链接后，发送非对称加密的公钥A给浏览器。
        3，浏览器生成随机数，作为对称加密的密钥B（要传输的明文数据）。
        4，浏览器使用服务器返回的公钥A，对自己生成的对称加密密钥B进行加密，得到密钥C。
        5，浏览器将密钥C发送给服务器
        6，服务器使用自己的私钥D对接受的密钥C进行解密，得到对称加密密钥B。
        7，浏览器和服务器之间使用密钥B作为对称加密密钥进行通信。
————————————————
版权声明：本文为CSDN博主「梦梦~~」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_46540738/article/details/121659035

# time_wait状态

![img](https://img-blog.csdnimg.cn/202105081132508.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mzc2MDU0Mg==,size_16,color_FFFFFF,t_70)

为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？

虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可能最后一个ACK丢失。所以TIME_WAIT（时间等待）状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。
————————————————
版权声明：本文为CSDN博主「程序媛格格酱」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/weixin_43760542/article/details/116521617



# 拥塞(se)控制

在某段时间，若对⽹络中某⼀资源的需求超过了该资源所能提供的可⽤部分，⽹络的性能就要变坏。这种情况就叫拥塞。**拥塞控制就是为了防⽌过多的数据注⼊到⽹络中**，这样就可以使⽹络中的路由器或链路不致过载。拥塞控制所要做的都有⼀个前提，就是⽹络能够承受现有的⽹络负荷。拥塞控制是⼀个全局性的过程，涉及到所有的主机，所有的路由器，以及与降低⽹络传输性能有关的所有因素。相反，流量控制往往是点对点通信量的控制，是个端到端的问题。**流量控制所要做到的就是抑制发送端发送数据的速率，以便使接收端来得及收。**  

为了进⾏拥塞控制， TCP 发送⽅要维持⼀个 **拥塞窗⼝(cwnd)** 的状态变量。拥塞控制窗⼝的⼤⼩取决于⽹络的拥塞程度，并且动态变化。发送⽅让⾃⼰的发送窗⼝取为拥塞窗⼝和接收⽅的接受窗⼝中较⼩的⼀个。  

TCP的拥塞控制采⽤了四种算法，即 **慢开始** 、 **拥塞避免** 、 **快重传** 和 **快恢复**。在⽹络层也可以使路由器采⽤适当的分组丢弃策略（如主动队列管理 AQM），以减少⽹络拥塞的发⽣。  

1、**慢开始**： 慢开始算法的思路是当主机开始发送数据时，如果⽴即把⼤量数据字节注⼊到⽹络，那么可能会引起⽹络阻塞，因为现在还不知道⽹络的符合情况。经验表明，较好的⽅法是先探测⼀下，即由⼩到⼤逐渐增⼤发送窗⼝，也就是由⼩到⼤逐渐增⼤拥塞窗⼝数值。
cwnd初始值为1，每经过⼀个传播轮次， cwnd加倍。

2、**拥塞避免**： 拥塞避免算法的思路是让拥塞窗⼝cwnd缓慢增⼤，即每经过⼀个往返时间RTT就把发送放的cwnd加1  

3、**快重传与快恢复**：在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery， FRR）是⼀种拥塞控制算法，它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了， TCP 将会使⽤定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到⼀个不按顺序的数据段，它会⽴即给发送机发送⼀个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并⽴即重传这些丢失的数据段。有了 FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某⼀段很短的时间内丢失时，它则不能很有效地⼯作 。

# 一致性哈希算法

https://blog.csdn.net/wdj_yyds/article/details/124710751

负载均衡

![img](https://img-blog.csdnimg.cn/img_convert/63a0ccac588b0fa986c577f47fa9f408.png)

能应对分布式系统的负载均衡算法：哈希算法

![img](https://img-blog.csdnimg.cn/img_convert/ddc561a7fc235e6717872ea3c5d1e3e4.png)

**哈希算法**虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。

例如：当 3 个节点不能满足业务需求了，这时我们增加了一个节点，节点的数量从 3 变化为 4，意味取模哈希函数中基数的变化，这样会导致大部分映射关系改变，如下图

![img](https://img-blog.csdnimg.cn/img_convert/3c6ca9256121255c98054aad23e9c59e.png)

**一致性哈希**是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。

**两步哈希**：

- **第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；**
- **第二步：当对数据进行存储或访问时，对数据进行哈希映射；**

![img](https://img-blog.csdnimg.cn/img_convert/3e7982c42f425ef2dc9ad51a7dab43c9.png)

一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。

一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。

为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入**虚拟节点**，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。



# 分布式系统

分布式系统是由许多计算机节点组成，为了完成单个计算机无法完成的任务，通过网络通信，共同协调，组成一个复杂的系统，利用更多的计算机节点，处理更大的数据量和更高的并发量。

## **分布式**

分布式（distributed）是为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段，将一个业务拆分成不同的子业务，分布在不同的机器上执行。服务之间通过远程调用协同工作，对外提供服务。

该领域需要解决的问题极多，在不同的技术层面上，又包括：分布式缓存、分布式数据库、分布式计算、分布式文件系统等，一些技术如MQ、Redis、zookeeper等都跟分布式有关。

从理念上讲，分布式的实现有两种形式：

​	**水平扩展**：当一台机器扛不住流量时，就通过添加机器的方式，将流量平分到所有服务器上，所有机器都可以提供 相同的服务；

​	**垂直拆分**：前端有多种查询需求时，一台机器扛不住，可以将不同的业务需求分发到不同的机器上，比如A机器处理余票查询的请求，B机器处理支付的请求。

## 集群

集群（cluster）是指在多台不同的服务器中部署相同应用或服务模块，构成一个集群，通过负载均衡设备对外提供服务。

两个特点

可扩展性：集群中的服务节点，可以动态的添加机器，从而增加集群的处理能力。

高可用性：如果集群某个节点发生故障，这台节点上面运行的服务，可以被其他服务节点接管，从而增强集群的高可用性。

两大能力

负载均衡：负载均衡能把任务比较均衡地分布到集群环境下的计算和网络资源。

集群容错：当我们的系统中用到集群环境，因为各种原因在集群调用失败时，集群容错起到关键性的作用。

## 微服务

微服务就是很小的服务，小到一个服务只对应一个单一的功能，只做一件事。这个服务可以单独部署运行，服务之间通过远程调用协同工作，每个微服务都是由独立的小团队开发，测试，部署，上线，负责它的整个生命周期。

## 多线程（multi-thread）

多线程是指程序中包含多个执行流，即在一个程序中可以同时运行多个不同的线程来执行不同的任务。多线程是为了提高CPU的利用率。

## 高并发（High Concurrency）

是一种系统运行过程中发生了一种“短时间内遇到大量请求”的情况，高并发对应的是访问请求，多线程是解决高并发的方法之一，高并发还可以通过分布式，集群，算法优化，数据库优化等方法解决。



## 分布式与集群的区别

分布式： 一个业务分拆多个子业务，部署在不同的服务器上
集群： 同一个业务，部署在多个服务器上。比如之前做电商网站搭的redis集群以及solr集群都是属于将redis服务器提供的缓存服务以及solr服务器提供的搜索服务部署在多个服务器上以提高系统性能、并发量解决海量存储问题。
————————————————
版权声明：本文为CSDN博主「这代码有毒啊」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/m0_67155975/article/details/123181607



## CAP定理

Consistency（一致性）：指数据在多个副本之间能够保持一致的特性（严格的一致性）

Availability（可用性）：系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据）

Partition tolerance（分区容错性）：分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障

![img](https://img-blog.csdnimg.cn/img_convert/8961f8b98c372625e119285e7d6d2852.png)

Spring Cloud在CAP法则上主要满足的是A和P法则，Dubbo和Zookeeper在CAP法则主要满足的是C和P法则。

CAP仅适用于原子读写的NOSQL场景中，并不适合数据库系统。现在的分布式系统具有更多特性比如扩展性、可用性等等，在进行系统设计和开发时，我们不应该仅仅局限在CAP问题上。



# mysql锁机制

数据库是一个多用户使用的共享资源。当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。

加锁是实现数据库并发控制的一个非常重要的技术。当事务在对某个数据对象进行操作前，先向系统发出请求，对其加锁。加锁后事务就对该数据对象有了一定的控制，在该事务释放锁之前，其他的事务不能对此数据对象进行更新操作。

**从数据的操作类型角度分为: 读锁和写锁**

读锁：又称为共享锁(Share Lock), 针对同一份数据, 多个读操作可以同时进行而不会相互影响;

写锁：又称为排他锁(Exclusive Lock), 当前写操作没有完成前, 它会阻断其他写锁和读锁;

对于InnoDB引擎, 读锁和写锁既可以加在表上, 也可以加在行上;



**从数据的操作力度(锁的粒度)角度分为: 表锁和行锁, 页锁**

**锁的类型**：

1.表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。

2.行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

3.页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

**锁的优化策略**

   1.读写分离

2. 分段加锁
3. 减少锁持有的时间
4. 多个线程尽量以相同的顺序去获取资源
5. 不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效率不如一次加一把大锁。



# select for update加表锁还是行锁？

如果查询条件用了索引/主键，那么select … for update就会进行行锁。

如果是普通字段(没有索引/主键)，那么select … for update就会进行锁表。

**如果我们的删除/修改语句是没有命中索引的，哪么，则会锁住整个表，这在性能上的影响还是挺大的**



# MVCC

## 对MVCC的理解

全称Multi-Version Concurrency Control、就是一种多并发版本控制器、通俗点就是一种并发控制的方法，一般用于数据库中对数据库的并发访问。Mysql中的innoDB中就是使用这种方法来提高读写事务控制的、他大大提高了读写事务的并发性能，原因是MVCC是一种不采用锁来控制事物的方式，是一种非堵塞、同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题。

总之：MVCC是通过保存数据的历史版本，根据比较版本号来处理数据是否显示，从而达到读取数据的时候不需要加锁就可以保证事务隔离性的效果。

## 当前读和快照读

1. 在高并发情况下，当前读是获取最新记录，并且不允许其他事务修改这个数据。
2.  当前读是加了锁的、加的是一种悲观锁。而快照读是没加锁的。 
3. 快照读获取的则是单纯的 SELECT 语句，取的有可能是事务未提交的数据。

## MVCC实现原理

MVCC的实现原理是依靠：**记录中的3个隐含字段**、**undo log日志**、**Read View**实现的。

1、隐含字段

​	DB_TRX_ID:记录操作该数据事务的事务id；
​    DB_ROLL_PTR：指向上一个版本数据在undo log里的位置指针
​    DB_ROW_ID：隐藏ID，当创建表没有合适的索引作为聚集索引时，会用该隐藏ID创建聚集索引

2、undo log日志

insert undo log：事务进行插入操作时产生、在事务回滚时需要，提交事务后可以被立即丢

update undo log：进行update、delete时产生的undo log、不仅在回滚事务时需要、在快照读时也需要。所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除（purge类似jvm中的gc垃圾回收器）

3、Read View

read view读视图就是在进行快照读时会产生一个read view视图、在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID(当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大)。

总的来说就是用来记录发生快照读那一刻所有的记录，当你下次就算有执行新的事务记录改变了，read view没变，读出来的数据依然是不变的。

而隔离级别中的RR（可重复读）、和RC（提交读）不同就是差在快照读时

前者创建一个快照和Read View，并且下次快照读时使用的还是同一个Read View所以其他事务修改数据对他是不可见的、解决了不可重复读问题。

后者则是每次快照读时都会产生新的快照和Read View、所以就会产生不可重复读问题。


## MVCC原理总结

InnoDB 每一行数据都有一个指向上一个版本数据在undo log日志里的位置指针。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。

MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务的隔离性。

# NGINX

https://blog.csdn.net/qq_58467694/article/details/125191080

Nginx 是一个 web 服务器和反向代理服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP 协议。

Nginx是一个 轻量级/高性能的反向代理Web服务器，他实现非常高效的反向代理、负载平衡，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如：新浪、网易、 腾讯等。

**Nginx负载均衡的算法怎么实现的?策略有哪些?**

- 轮询(默认)
- 权重 weight
- ip_hash( IP绑定)
- fair(第三方插件)
- url_hash(第三方插件)

**为什么用Nginx**

跨平台、配置简单、反向代理、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发，内存消耗小：开启10个nginx才占150M内存 ，nginx处理静态文件好，耗费内存少
而且Nginx内置的健康检查功能：如果有一个服务器宕机，会做一个健康检查，再发送的请求就不会发送到宕机的服务器了。重新将请求提交到其他的节点上。
使用Nginx的话还能：
                1、节省宽带：支持GZIP压缩，可以添加浏览器本地缓存
                2、稳定性高：宕机的概率非常小
                3、接收用户请求是异步的

**为什么Nginx性能高**

因为他的事件处理机制：异步非阻塞事件处理机制：运用了epoll模型，提供了一个队列，排队解决

**为什么不采用多线程**

Nginx:采用单线程来异步非阻塞处理请求（管理员可以配置Nginx主进程的工作进程的数量），不会为每个请求分配cpu和内存资源，节省了大量资源，同时也减少了大量的CPU的上下文切换，所以才使得Nginx支持更高的并发。

**Nginx应用场景**

1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
2、虚拟主机。可以实现在一台服务器虚拟出多个网站，例如个人网站使用的虚拟机。
3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做4、反向代理。并且多台服务器可以平均分担负载，不会应为某台服务器负载高宕机而某台服务器闲置的情况。
5、nginx 中也可以配置安全管理、比如可以使用Nginx搭建API接口网关,对每个接口服务进行拦截。

**Nginx四大功能**

1、正向代理        在客户端(浏览器)配置代理服务器，通过代理服务器进行互联网访问。
2、反向代理        我们只需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返回给客户端
此时反向代理服务器和目标服务器对外就是一个服务器,暴露的是代理服务器地址，隐藏了真实服务器IP地址。
3、负载均衡        单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器
上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡。
4、动静分离       为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力

# 自我介绍

面试官好，我叫XXX，现就读于北京邮电大学电子信息专业，攻读硕士学位。

在校期间，我认真学习各项专业知识，掌握操作系统、计算机网络、数据结构等基础知识。  熟悉Java常用技术栈，熟悉关系型数据库MySQL语法，了解Redis的使用以及部分原理。能够熟练使用springboot、SpringCloud等框架进行开发，了解IOC以及AOP实现原理  ，熟练使用idea等进行项目开发。

我曾经使用过开发了一个校园知识刷题系统，实现针对学校的思政类考试所需要复习储备的知识管理，网站前端采用基于Vue等技术进行展示，后端采用基于SpringCloud的微服务架构。  

我也参与了实验室的一个安卓App开发项目，主要负责。。。

